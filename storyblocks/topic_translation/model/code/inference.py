#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
Module:
Created: 2022-03-30

Description:

    inference functions for pytorch serving container for topic translation

    yes this is insane overkill for what is basically just a simple matrix multiplication but hey
    whatcha gonna do this is the framework all our other models are in so

"""
import datetime
import json
import os

import boto3
import numpy as np
from sagemaker_inference import content_types, errors
from scipy.sparse import dok_matrix


class StoryblocksCustomError(errors.GenericInferenceToolkitError):
    def __init__(self, message):
        super().__init__(400, message)


def timer(func):
    def wrapped_func(*args, **kwargs):
        t0 = datetime.datetime.now()
        print(f'entering {func.__name__} at {t0}')
        x = func(*args, **kwargs)
        t1 = datetime.datetime.now()
        print(f'exiting {func.__name__} at {t1}')
        print(f'total time in {func.__name__}: {t1 - t0}')
        return x

    return wrapped_func


# get the weight arrays and load them into memory
TRANSLATION_ARRAYS = {}


@timer
def load_arrays(src_class: str = 'video', tgt_class: str = 'audio'):
    global TRANSLATION_ARRAYS
    s3 = boto3.resource('s3')
    bucket = s3.Bucket('videoblocks-ml')
    prefix = f'models/topic-translation/{src_class}-{tgt_class}/prod/arrays'

    for obj_summary in bucket.objects.filter(Prefix=prefix):
        basename = os.path.basename(obj_summary.key)
        src_type, tgt_type = (os.path.splitext(basename)[0]).split('_')
        f_local = f"/tmp/{basename}"
        obj = bucket.Object(key=obj_summary.key)
        obj.download_file(Filename=f_local)
        TRANSLATION_ARRAYS[src_type, tgt_type] = np.load(f_local)


load_arrays('video', 'audio')


def parse_json_input(input_data):
    try:
        j = json.loads(input_data)
        src_content_type = j['srcContentType']
        tgt_content_type = j['tgtContentType']
        dim = j['sparseVector']['dim']
        vector_dict = j['sparseVector']['vector']

        vector = np.zeros(dim)
        for (idx_str, val) in vector_dict.items():
            idx = int(idx_str)
            vector[idx] = val

        return src_content_type, tgt_content_type, vector
    except (KeyError, TypeError):
        raise StoryblocksCustomError(
            f"payloads for content type {content_types.JSON} must have json bodies with keys "
            f"\"srcContentType\", \"tgtContentType\", and \"sparseVector\". futhermore, the value "
            f"for \"sparseVector\" must be an object with keys \"dim\" and \"vector\"")
    except IndexError:
        raise StoryblocksCustomError(
            "sparseVector.vector contains keys greater that sparseVector.dim")


@timer
def model_fn(model_dir):
    return None


@timer
def input_fn(input_data, content_type):
    """A default input_fn that can handle JSON, CSV and NPZ formats. parse all into a dense
    topic vector

    Args:
        input_data: the request payload serialized in the content_type format
        content_type: the request content_type

    Returns:
        ori_imgs (list of np.ndarray) the original image as a cv2 np array
        framed_imgs (list of np.ndarray) a resized and rescaled version of each image in ori_imgs
        framed_metas (list of tuples) a list of tuples of scaling information, where each tuple
            has components new_w, new_h, old_w, old_h, padding_w, padding_h
        pred_threshold (float): threshold for filtering detection predictions
        iou_threshold (float): threshold for iou filtering in nms postprocessing of detections

    """
    if content_type == content_types.JSON:
        return parse_json_input(input_data)
    else:
        raise errors.UnsupportedFormatError(content_type)


@timer
def predict_fn(data, model):
    """just matrix multiplication, y'all

    Args:
        data: tuple of inputs generated by custom input_fn above
        model: PyTorch model loaded in memory by model_fn

    Returns: a vector translated into the desired content type

    """
    src_content_type, tgt_content_type, vector = data
    translation_array = TRANSLATION_ARRAYS[src_content_type, tgt_content_type]
    dense_output = translation_array @ vector
    out_dim = dense_output.shape[0]
    dok_output = dok_matrix(dense_output.reshape(1, out_dim))
    return {'dim': out_dim,
            'vector': {str(idx): val for ((_, idx), val) in dok_output.items()}}
